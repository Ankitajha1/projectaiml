{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Read the data from h5py file and understand the train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f = h5py.File('SVHN_single_grey1.h5','r')\n",
    "h5f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the splited train, validation and test data\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "\n",
    "X_val = h5f['X_val'][:]\n",
    "y_val = h5f['y_val'][:]\n",
    "\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X_train is (42000, 32, 32)\n",
      "size of y_train is (42000,)\n",
      "size of X_val is (60000, 32, 32)\n",
      "size of y_val is (60000,)\n",
      "size of X_test is (18000, 32, 32)\n",
      "size of y_test is (18000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'size of X_train is {X_train.shape}')\n",
    "print(f'size of y_train is {y_train.shape}')\n",
    "\n",
    "print(f'size of X_val is {X_val.shape}')\n",
    "print(f'size of y_val is {y_val.shape}')\n",
    "\n",
    "print(f'size of X_test is {X_test.shape}')\n",
    "print(f'size of y_test is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the training dataset(X_train )has 42k records and the test dataset has 18k records each record being 32*32 in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Reshape and normalize the train and test features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train is (42000, 1024)\n",
      "shape of X_val is (60000, 1024)\n",
      "shape of X_test is (18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32*32)\n",
    "X_val = X_val.reshape(X_val.shape[0], 32*32)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32*32)\n",
    "\n",
    "print(f'shape of X_train is {X_train.shape}')\n",
    "print(f'shape of X_val is {X_val.shape}')\n",
    "print(f'shape of X_test is {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /=255\n",
    "X_val /=255\n",
    "X_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is 0.0\n",
      "max value is 0.9998999834060669\n"
     ]
    }
   ],
   "source": [
    "print(f'min value is {X_train.min()}')\n",
    "print(f'max value is {X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization : Min value is 0.0 and Max value is 0.9998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: One hot encode the labels for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrix\n",
    "# Convert y_train, y_val and  y_test\n",
    "# number of classes : 10\n",
    "# we are doing this to use categorical_crossentropy as loss\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (42000, 10)\n",
      "One value of y_train: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_val = to_categorical(y_val, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"One value of y_train:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Define the model architecture using Tensorflow with a flatten layer followed by dense layers with activation as Relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of neurons in first layer : 256\n",
    "Number of neurons in last layer : number of classes\n",
    "Activation function in first layer : relu\n",
    "Activation function in last layer : softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Compile the model with loss as categorical cross-entropy and adam optimizers. Use accuracy as the metric for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our model\n",
    "    Loss : \"Categorical_crossentropy\"\n",
    "  Metrics: \"accuracy\"\n",
    "         Optimizer: \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 1.8229 - accuracy: 0.4096 - val_loss: 1.8708 - val_accuracy: 0.5737\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 1.0821 - accuracy: 0.6856 - val_loss: 1.4681 - val_accuracy: 0.7079\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.8876 - accuracy: 0.7419 - val_loss: 1.1858 - val_accuracy: 0.7347\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.7740 - accuracy: 0.7759 - val_loss: 0.9614 - val_accuracy: 0.7754\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.6981 - accuracy: 0.7970 - val_loss: 0.8310 - val_accuracy: 0.7843\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.6397 - accuracy: 0.8146 - val_loss: 0.7405 - val_accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.5982 - accuracy: 0.8285 - val_loss: 0.6722 - val_accuracy: 0.8133\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.5574 - accuracy: 0.8408 - val_loss: 0.6324 - val_accuracy: 0.8242\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.5306 - accuracy: 0.8479 - val_loss: 0.6268 - val_accuracy: 0.8224\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.5178 - accuracy: 0.8497 - val_loss: 0.6103 - val_accuracy: 0.8317\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.4838 - accuracy: 0.8592 - val_loss: 0.5985 - val_accuracy: 0.8308\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.4677 - accuracy: 0.8634 - val_loss: 0.5770 - val_accuracy: 0.8396\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.4464 - accuracy: 0.8697 - val_loss: 0.5713 - val_accuracy: 0.8416\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.4259 - accuracy: 0.8768 - val_loss: 0.5676 - val_accuracy: 0.8433\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.4317 - accuracy: 0.8738 - val_loss: 0.5806 - val_accuracy: 0.8389\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4098 - accuracy: 0.8808 - val_loss: 0.5734 - val_accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.3997 - accuracy: 0.8849 - val_loss: 0.5740 - val_accuracy: 0.8423\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.3867 - accuracy: 0.8884 - val_loss: 0.5566 - val_accuracy: 0.8453\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.3739 - accuracy: 0.8918 - val_loss: 0.5479 - val_accuracy: 0.8512\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 1s 16ms/step - loss: 0.3632 - accuracy: 0.8937 - val_loss: 0.5537 - val_accuracy: 0.8496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19984be6c08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train,y_train, epochs = 20, batch_size = 700, verbose=1, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Print the loss and accuracy for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 0s 792us/step - loss: 0.5537 - accuracy: 0.8496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.553717851638794, 0.8495555520057678]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
